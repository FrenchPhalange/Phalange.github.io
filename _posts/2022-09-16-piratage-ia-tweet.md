---
layout: post
title:  "Une IA pirat√©e avec un tweet !"
date:   2022-09-16 17:56:57 +0200
image:  '/images/blog/piratage-ia-tweet/header.png'
tags:   [IA, Cybers√©curit√©]
---

Une intelligence artificielle pirat√©e avec un tweet ???

Remoteli est un bot Twitter cens√© vous aider √† trouver du travail en remote, mais... on a r√©ussi √† lui faire raconter n'importe quoi, gr√¢ce √† une toute nouvelle m√©thode d'**injection de requ√™te** ! Explications.

Remoteli est donc cens√© r√©pondre automatiquement aux tweets contenant les mots "remote work" et "remote jobs", en s'appuyant sur une IA pour g√©n√©rer ses r√©ponses.

L'IA en question est le c√©l√®bre GPT-3, d√©velopp√© par la soci√©t√© OpenAI (qui est √©galement √† l'origine de DALL¬∑E 2). 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/piratage-ia-tweet/1570803945655906312-FcyX6olXwAMb1ah.jpg" draggable="false">
  </div>
</div>

GPT-3 est capable g√©n√©rer des textes en langage naturel tr√®s r√©aliste pour r√©pondre √† n'importe quelle requ√™te.

Pour enseigner √† GPT-3 la mani√®re r√©pondre, on va lui donner plusieurs exemples de questions/r√©ponses qui respectent le format attendu. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/piratage-ia-tweet/1570803951032999937-FcyM9fKXoAE2XW-.jpg" draggable="false">
  </div>
</div>

Pour communiquer avec GPT-3, on utilise une API sur laquelle on envoie cette s√©rie d'exemples, suivie de la question √† laquelle il doit r√©pondre.

Par exemple sur cette requ√™te, GPT-3 nous dira "La r√©ponse est xxx" (je vous laisse faire le calcul chez vous, sans calculette üòú) 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/piratage-ia-tweet/1570803956254912515-FcyOfYFXgAACWni.jpg" draggable="false">
  </div>
</div>

Au passage, ce r√©seau de neurones est archi puissant : en lui donnant seulement 3 exemples de code source en JavaScript, on est capable de lui faire √©crire une appli qui r√©pond √† un cahier des charges simple üò± 

<div class="gallery-box">
  <div class="gallery">
<video style="height:350px; object-fit:cover" controls>  <source src="/images/blog/piratage-ia-tweet/1570803986403557376-wVhngSSBQoF4FDZI.mp4" type="video/mp4"></video>  </div>
</div>

Cependant, cet apprentissage peut √™tre **d√©tourn√©** si la derni√®re question est contr√¥l√©e par l'utilisateur.

Prenons un exemple o√π GPT-3 serait int√©gr√© √† une interface o√π n'importe qui peut poser des questions de maths. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/piratage-ia-tweet/1570803992221061120-FcyRiUdXEAABRPo.jpg" draggable="false">
  </div>
</div>

Dans ce cas, l'appli va concat√©ner la cha√Æne de caract√®res en blanc avec la question de l'utilisateur, et envoyer le tout √† GPT-3.

Mais l'IA n'a **aucun moyen de diff√©rencier** ce qui a √©t√© √©crit par le dev de ce qui provient de l'utilisateur.

Et l'utilisateur peut donc exploiter cette vuln√©rabilit√© en envoyant un faux exemple d'entra√Ænement empoisonn√©. GPT-3 pense que ce troisi√®me exemple fait partie de l'entra√Ænement, et risque donc de r√©pondre "LOL" √† la derni√®re requ√™te ! 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/piratage-ia-tweet/1570803999242358786-FcyVEVdXgAE9fP7.jpg" draggable="false">
  </div>
</div>

Cette technique d'injection a √©t√© d√©couverte en d√©but de semaine par l'expert Riley Goodside.

Il n'aura donc fallu que 3 jours pour que certains petits malins de Twitter ne trouvent sa premi√®re victime, qui n'√©tait autre que le bot Remoteli üòÖ 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/piratage-ia-tweet/1570804005101772806-FcyZDiWWAAUVMTn.jpg" draggable="false">
  </div>
</div>

Des attaques similaires existent d√©j√† dans le d√©veloppement web : on retrouve exactement le m√™me principe qu'une injection SQL ou d'une faille XSS.

Voil√† donc une nouvelle le√ßon apprise par les expert¬∑es en intelligence artificielle aujourd'hui : **never trust user input** !

Merci d'avoir suivi cet article ü•∞ Pour d√©couvrir un autre cas de manipulation d'une IA, je vous invite √† lire [cet autre article](/blog/dall-e-2-triche) que j'avais √©crit √† propos de l'inclusivit√© chez OpenAI et des d√©rives √©thiques.


